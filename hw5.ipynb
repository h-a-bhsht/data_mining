{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ln6_GyNsYz7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad61007f-262d-4c89-a24b-1e0fb5184ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled shape: (1567, 474)\n",
            "Mean (approx 0) of first 5 features: [ 1.62332035e-15 -5.07372631e-15 -5.71336214e-15 -1.26963603e-16\n",
            "  0.00000000e+00]\n",
            "Std  (approx 1) of first 5 features: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = pd.read_csv(\"secom.data\", sep=\" \", header=None)\n",
        "y = pd.read_csv(\"secom_labels.data\", sep=\" \", header=None)[0]\n",
        "variances = X.var(axis=0, skipna=True)\n",
        "non_constant_cols = variances[variances > 0].index\n",
        "X_nc = X[non_constant_cols].copy()\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_imputed = imputer.fit_transform(X_nc)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "print(\"Scaled shape:\", X_scaled.shape)\n",
        "print(\"Mean (approx 0) of first 5 features:\", X_scaled[:, :5].mean(axis=0))\n",
        "print(\"Std  (approx 1) of first 5 features:\", X_scaled[:, :5].std(axis=0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 2"
      ],
      "metadata": {
        "id": "K-DHNwS2N5_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "\n",
        "k = 20\n",
        "start = time.time()\n",
        "mi_selector = SelectKBest(mutual_info_classif, k=k)\n",
        "X_mi = mi_selector.fit_transform(X_scaled, y)\n",
        "end = time.time()\n",
        "execution_time = end - start\n",
        "selected_mi_indices = mi_selector.get_support(indices=True)\n",
        "print(\"Top 20 MI Feature Indices:\", selected_mi_indices)\n",
        "print(f\"MI execution time: {execution_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "k = 20\n",
        "start = time.time()\n",
        "rfe = RFE(estimator=rf, n_features_to_select=k, step=1)\n",
        "rfe.fit(X_scaled, y)\n",
        "end = time.time()\n",
        "execution_time = end - start\n",
        "selected_rfe_indices = np.where(rfe.support_ == True)[0]\n",
        "print(\"RFE selected feature indices:\", selected_rfe_indices)\n",
        "print(f\"RFE execution time: {execution_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "De3X_38S1j47",
        "outputId": "e3c193b7-5dfc-42df-eea7-146c990c4b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 MI Feature Indices: [ 39  51  60 115 121 126 211 230 243 276 328 333 337 348 387 425 455 457\n",
            " 461 473]\n",
            "MI execution time: 2.36 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 3"
      ],
      "metadata": {
        "id": "ATpawb7GVCiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k= 20\n",
        "U, S, VT = np.linalg.svd(X_scaled, full_matrices=False)\n",
        "V = VT[:k, :]\n",
        "scores = np.zeros(V.shape[1])\n",
        "for j in range(V.shape[1]):\n",
        "    scores[j] = np.sum((S[:k]**2) * (V[:, j]**2))\n",
        "ranked_indices = np.argsort(scores)[::-1]\n",
        "top_20_indices = ranked_indices[:20]\n",
        "print(\"Top 20 SVD-based feature indices:\", top_20_indices)"
      ],
      "metadata": {
        "id": "xvUDzPPNVEZY",
        "outputId": "51b0407c-2cf2-48c1-bab6-dc3f6d61191a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 SVD-based feature indices: [317 413 214 315 212 411 140 239 342 412 316 213 281 242 143 284 283 184\n",
            " 178 389]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 4"
      ],
      "metadata": {
        "id": "frdL0ncfZ_l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# VT has shape (n_components, n_features)\n",
        "pc1_loadings = VT[0, :]   # loadings for first component\n",
        "pc2_loadings = VT[1, :]   # loadings for second component\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(pc1_loadings, pc2_loadings, s=10)\n",
        "plt.axhline(0, color='grey', linewidth=0.5)\n",
        "plt.axvline(0, color='grey', linewidth=0.5)\n",
        "plt.xlabel(\"Loading on PC1\")\n",
        "plt.ylabel(\"Loading on PC2\")\n",
        "plt.title(\"Loading plot: PC1 vs PC2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "noise = 0.05 * rng.standard_normal(X_scaled.shape)\n",
        "X_scaled_noisy = X_scaled + noise\n",
        "# --- RFE on noisy data ---\n",
        "start = time.time()\n",
        "rfe_noisy = RFE(estimator=rf, n_features_to_select=k, step=1)\n",
        "rfe_noisy.fit(X_scaled_noisy, y)\n",
        "end = time.time()\n",
        "selected_rfe_indices_noisy = np.where(rfe_noisy.support_ == True)[0]\n",
        "print(\"RFE selected feature indices (noisy):\", selected_rfe_indices_noisy)\n",
        "print(f\"RFE (noisy) execution time: {end - start:.2f} seconds\")\n",
        "\n",
        "# --- SVD-based ranking on noisy data ---\n",
        "U_n, S_n, VT_n = np.linalg.svd(X_scaled_noisy, full_matrices=False)\n",
        "V_n = VT_n[:k, :]\n",
        "scores_n = np.zeros(V_n.shape[1])\n",
        "for j in range(V_n.shape[1]):\n",
        "    scores_n[j] = np.sum((S_n[:k]**2) * (V_n[:, j]**2))\n",
        "ranked_indices_n = np.argsort(scores_n)[::-1]\n",
        "top_20_indices_noisy = ranked_indices_n[:20]\n",
        "print(\"Top 20 SVD-based feature indices (noisy):\", top_20_indices_noisy)\n",
        "orig_rfe = set(selected_rfe_indices)\n",
        "noisy_rfe = set(selected_rfe_indices_noisy)\n",
        "\n",
        "orig_svd = set(top_20_indices)\n",
        "noisy_svd = set(top_20_indices_noisy)\n",
        "intersection_rfe = orig_rfe & noisy_rfe\n",
        "intersection_svd = orig_svd & noisy_svd\n",
        "print(\"RFE overlap:\", len(intersection_rfe), \"features\")\n",
        "print(\"SVD overlap:\", len(intersection_svd), \"features\")\n",
        "print(\"RFE overlapping indices:\", sorted(list(intersection_rfe)))\n",
        "print(\"SVD overlapping indices:\", sorted(list(intersection_svd)))\n"
      ],
      "metadata": {
        "id": "e3XVZ5fvaAl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 5"
      ],
      "metadata": {
        "id": "4bwAsGl4zckM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# example split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# subsets\n",
        "X_train_mi = X_train[:, selected_mi_indices]\n",
        "X_test_mi = X_test[:, selected_mi_indices]\n",
        "\n",
        "X_train_rfe = X_train[:, selected_rfe_indices]\n",
        "X_test_rfe = X_test[:, selected_rfe_indices]\n",
        "\n",
        "X_train_svd = X_train[:, top_20_indices]\n",
        "X_test_svd = X_test[:, top_20_indices]\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "def eval_subset(Xtr, Xte):\n",
        "    clf.fit(Xtr, y_train)\n",
        "    y_pred = clf.predict(Xte)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "    return acc, f1\n",
        "\n",
        "\n",
        "acc_mi, f1_mi = eval_subset(X_train_mi, X_test_mi)\n",
        "acc_rfe, f1_rfe = eval_subset(X_train_rfe, X_test_rfe)\n",
        "acc_svd, f1_svd = eval_subset(X_train_svd, X_test_svd)\n",
        "set_rfe = set(selected_rfe_indices)\n",
        "set_svd = set(top_20_indices)\n",
        "intersection = set_rfe & set_svd\n",
        "overlap_count = len(intersection)\n",
        "overlap_percent_rfe = overlap_count / len(set_rfe) * 100\n",
        "overlap_percent_svd = overlap_count / len(set_svd) * 100\n",
        "\n"
      ],
      "metadata": {
        "id": "9_ANJp5fzd27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}